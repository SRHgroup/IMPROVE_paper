{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import datetime\n",
    "import xgboost\n",
    "import sklearn\n",
    "import sklearn.ensemble as ensemble\n",
    "#from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from xgboost import XGBRFClassifier\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "from platform import python_version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The scikit-learn version is 1.0.2.\n"
     ]
    }
   ],
   "source": [
    "# costumized stuff  \n",
    "patient_data = True\n",
    "Simple =  True\n",
    "print('The scikit-learn version is {}.'.format(sklearn.__version__))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_include = ['cohort','Patient','HLA_allele','Mut_peptide','response','Partition',\n",
    "                   'Aro','mw','pI', 'Inst', 'CysRed','RankEL','RankBA','NetMHCExp',\n",
    "                        'Expression','SelfSim','Prime','PropHydroAro','HydroCore',\n",
    "                        'PropSmall','PropAro','PropBasic','PropAcidic','DAI','Stability','Foreigness',\n",
    "                        'CelPrev','PrioScore','CYT','HLAexp','Monocytes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the data with or without the patient data for tumor microenviroment and with or withput selected cols\n",
    "#print(\"running model with only_imp_cols:\" + only_imp_cols + \"and patient_data\"+ patient_data)\n",
    "\n",
    "if patient_data == True and Simple == False: \n",
    "    cols_to_drop = ['cohort','Patient','HLA_allele','Mut_peptide','response','Partition']\n",
    "    Model = \"TME_included\"\n",
    "if patient_data == False and Simple == False: \n",
    "    cols_to_drop = ['cohort','Patient','HLA_allele','Mut_peptide','response','Partition',\n",
    "                   'CYT','HLAexp','Monocytes']\n",
    "    Model = \"TME_excluded\"\n",
    "if patient_data == False and Simple == True: \n",
    "    cols_to_drop = ['cohort','Patient','HLA_allele','Mut_peptide','response','Partition',\n",
    "                   'CelPrev','PrioScore','CYT','HLAexp','Monocytes'] #\n",
    "    Model = \"Simple\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = pd.read_csv('../../data/03_1_feature_partition_data/03_2_final_peptide_features_Partition_V2.txt', sep='\\t')\n",
    "#data = pd.read_csv('../../data/03_data_for_CV/IMPROVE/03_final_peptide_features_Partition.txt', sep='\\t')\n",
    "data = pd.read_csv('../../data/03_data_for_CV/IMPROVE/03_final_peptide_features_Partition_prime1.txt', sep='\\t')\n",
    "#data = pd.read_csv('../../data/03_1_feature_partition_data/03_2_final_peptide_features_Partition_old.txt', sep='\\t')\n",
    "Var_importance_filename = '../../results/5_fold_CV/'+Model+'/Feature_importance_' + Model +'.txt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple\n"
     ]
    }
   ],
   "source": [
    "print(Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        cohort  Patient  HLA_allele  Mut_peptide  response  Partition  \\\n",
      "0      bladder  BC-1233  HLA-A11:01   GSHASSSARR         0          0   \n",
      "1      bladder  BC-1233  HLA-A11:01   GTWASRELLR         0          0   \n",
      "2      bladder  BC-1233  HLA-A11:01  VTNDTEGDINY         0          0   \n",
      "3      bladder  BC-1233  HLA-A11:01    RVASRFSGF         0          0   \n",
      "4      bladder  BC-1233  HLA-A11:01    STTLTNWQR         0          0   \n",
      "...        ...      ...         ...          ...       ...        ...   \n",
      "17515   Basket    RH-22  HLA-A30:01   HVEVSPAVTK         0          2   \n",
      "17516   Basket    RH-22  HLA-A30:01    KVAQNLLDK         0          2   \n",
      "17517   Basket    RH-22  HLA-A30:01    MYKDHSIYI         0          2   \n",
      "17518   Basket    RH-22  HLA-A30:01    HQWLSCMYK         0          2   \n",
      "17519   Basket    RH-22  HLA-A30:01    SGMGAHLVV         0          2   \n",
      "\n",
      "            Aro         mw         pI        Inst  ...  PropBasic  PropAcidic  \\\n",
      "0      0.000000  1015.0423  12.500110  104.800000  ...   0.333333    0.000000   \n",
      "1      0.100000  1188.3362  10.397771    8.970000  ...   0.166667    0.166667   \n",
      "2      0.090909  1240.2302   3.380030   -8.445455  ...   0.000000    0.428571   \n",
      "3      0.222222  1026.1491  12.500109   30.288889  ...   0.200000    0.000000   \n",
      "4      0.111111  1106.1893  10.550002  -19.333333  ...   0.000000    0.000000   \n",
      "...         ...        ...        ...         ...  ...        ...         ...   \n",
      "17515  0.000000  1066.2082   7.549727   63.710000  ...   0.000000    0.166667   \n",
      "17516  0.000000  1028.2032   9.537298   -9.977778  ...   0.000000    0.200000   \n",
      "17517  0.222222  1169.3492   7.533794   35.200000  ...   0.200000    0.200000   \n",
      "17518  0.222222  1195.4130   8.530526  121.355556  ...   0.000000    0.000000   \n",
      "17519  0.000000   870.0280   7.550324   -9.977778  ...   0.200000    0.000000   \n",
      "\n",
      "            DAI  Stability  Foreigness   CelPrev  PrioScore       CYT  \\\n",
      "0      1.000000        1.9         0.0  0.992109        0.0  7.369494   \n",
      "1      1.086414        0.9         1.0  0.992139        0.0  7.369494   \n",
      "2      0.903205        5.5         0.0  0.992394        0.0  7.369494   \n",
      "3      0.558981        6.5         0.0  0.992193        0.0  7.369494   \n",
      "4      0.370361        1.7         0.0  0.992261        2.0  7.369494   \n",
      "...         ...        ...         ...       ...        ...       ...   \n",
      "17515  0.109530        5.0         0.0  0.995677        8.0  1.000302   \n",
      "17516  0.832405        0.9         0.0  0.995724        4.0  1.000302   \n",
      "17517  0.893308       10.0         0.0  0.995634        8.0  1.000302   \n",
      "17518  0.845739        0.8         0.0  0.995634        0.0  1.000302   \n",
      "17519  1.711602       27.0         0.0  0.995556        1.0  1.000302   \n",
      "\n",
      "           HLAexp  Monocytes  \n",
      "0      437.936041  22.964245  \n",
      "1      437.936041  22.964245  \n",
      "2      437.936041  22.964245  \n",
      "3      437.936041  22.964245  \n",
      "4      437.936041  22.964245  \n",
      "...           ...        ...  \n",
      "17515   28.533186   2.568216  \n",
      "17516   28.533186   2.568216  \n",
      "17517   28.533186   2.568216  \n",
      "17518   28.533186   2.568216  \n",
      "17519   28.533186   2.568216  \n",
      "\n",
      "[17520 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "data = data[cols_to_include]\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4]\n",
      "0\n",
      "3209\n",
      "Index(['Aro', 'mw', 'pI', 'Inst', 'CysRed', 'RankEL', 'RankBA', 'NetMHCExp',\n",
      "       'Expression', 'SelfSim', 'Prime', 'PropHydroAro', 'HydroCore',\n",
      "       'PropSmall', 'PropAro', 'PropBasic', 'PropAcidic', 'DAI', 'Stability',\n",
      "       'Foreigness'],\n",
      "      dtype='object')\n",
      "1\n",
      "2785\n",
      "Index(['Aro', 'mw', 'pI', 'Inst', 'CysRed', 'RankEL', 'RankBA', 'NetMHCExp',\n",
      "       'Expression', 'SelfSim', 'Prime', 'PropHydroAro', 'HydroCore',\n",
      "       'PropSmall', 'PropAro', 'PropBasic', 'PropAcidic', 'DAI', 'Stability',\n",
      "       'Foreigness'],\n",
      "      dtype='object')\n",
      "2\n",
      "4102\n",
      "Index(['Aro', 'mw', 'pI', 'Inst', 'CysRed', 'RankEL', 'RankBA', 'NetMHCExp',\n",
      "       'Expression', 'SelfSim', 'Prime', 'PropHydroAro', 'HydroCore',\n",
      "       'PropSmall', 'PropAro', 'PropBasic', 'PropAcidic', 'DAI', 'Stability',\n",
      "       'Foreigness'],\n",
      "      dtype='object')\n",
      "3\n",
      "4489\n",
      "Index(['Aro', 'mw', 'pI', 'Inst', 'CysRed', 'RankEL', 'RankBA', 'NetMHCExp',\n",
      "       'Expression', 'SelfSim', 'Prime', 'PropHydroAro', 'HydroCore',\n",
      "       'PropSmall', 'PropAro', 'PropBasic', 'PropAcidic', 'DAI', 'Stability',\n",
      "       'Foreigness'],\n",
      "      dtype='object')\n",
      "4\n",
      "2935\n",
      "Index(['Aro', 'mw', 'pI', 'Inst', 'CysRed', 'RankEL', 'RankBA', 'NetMHCExp',\n",
      "       'Expression', 'SelfSim', 'Prime', 'PropHydroAro', 'HydroCore',\n",
      "       'PropSmall', 'PropAro', 'PropBasic', 'PropAcidic', 'DAI', 'Stability',\n",
      "       'Foreigness'],\n",
      "      dtype='object')\n",
      "n sample: 50 RF AUC: 0.6444\n"
     ]
    }
   ],
   "source": [
    "# nested cross validation\n",
    "outfile = open(Var_importance_filename ,'w')\n",
    "n_sample = 50\n",
    "partitioning_list = data.Partition.unique()\n",
    "#partitioning_list.sort()\n",
    "print(partitioning_list)\n",
    "pred_df = pd.DataFrame()\n",
    "for i in partitioning_list:\n",
    "    av_pred_rf = 0\n",
    "    print(i)\n",
    "    for n in range(n_sample):  \n",
    "        test = data[data.Partition == i]\n",
    "        train = data[data.Partition != i]\n",
    "        info = test[['cohort',\"Mut_peptide\", \"HLA_allele\",\"Patient\",\"Partition\"]]\n",
    "        train_pos = train[train.response==1]\n",
    "        train_neg = train[train.response==0].sample(n=500, random_state=n) \n",
    "        train = shuffle(pd.concat([train_pos, train_neg], axis=0), random_state = 42).reset_index(drop=True)\n",
    "        train = train[~train.Mut_peptide.isin(test[\"Mut_peptide\"])]\n",
    "        X_train = train.drop(cols_to_drop, axis=1).reset_index(drop=True)\n",
    "        \n",
    "        y_train = train[\"response\"]\n",
    "        feature_list = list(X_train.columns)\n",
    "        \n",
    "\n",
    "\n",
    "        # Instantiate the RF and the MLP # \n",
    "        rf = RandomForestClassifier(random_state = 42, max_depth = 6, min_samples_leaf = 6,\n",
    "                                    n_estimators = 2000, n_jobs=-1) #class_weight={0:1,1:3}\n",
    "\n",
    "                # Train the models on training data\n",
    "        rf.fit(X_train, y_train)\n",
    "        \n",
    "        # pickle dumb model \n",
    "        pickle_model = '../../models/'+ Model +'/rf' + str(i) + '_' + Model +'_' + str(n) + '.pkl'\n",
    "        pickle.dump(rf, open(pickle_model, 'wb'))\n",
    "        \n",
    "        X_test = test.drop(cols_to_drop, axis=1).reset_index(drop=True)\n",
    "        y_test = test[\"response\"]  \n",
    "        len(X_test)\n",
    "\n",
    "        #Get fetures importance per partition\n",
    "        importances = list(rf.feature_importances_)\n",
    "        feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_list, importances)]\n",
    "        # Sort\n",
    "        feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "     #   [print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances]\n",
    "      #  gather all feature importance \n",
    "        for pair in feature_importances:\n",
    "            outfile.write(str(pair[0]) + \"\\t\" + str(pair[1]) + \"\\t\" + str(i) + \"\\n\")\n",
    "\n",
    "        prediction_rf = rf.predict_proba(X_test)\n",
    "\n",
    "        \n",
    "        av_pred_rf += prediction_rf\n",
    "    \n",
    "    pred_val_rf = av_pred_rf/n_sample\n",
    "        \n",
    "    pred_val_rf = pd.DataFrame(pred_val_rf[:,1])\n",
    "    pred_val_rf.reset_index(drop=True, inplace=True)\n",
    "    mapping = {pred_val_rf.columns[0]: \"prediction_rf\"}\n",
    "    pred_val_rf = pred_val_rf.rename(columns=mapping)\n",
    "\n",
    "    X_test.reset_index(drop=True, inplace=True)\n",
    "    y_test.reset_index(drop=True, inplace=True)\n",
    "    info.reset_index(drop=True, inplace=True)\n",
    "    print(len(X_test))\n",
    "    ped_df = pd.concat([info,X_test,y_test,pred_val_rf],axis = 1)\n",
    "    ped_df[\"Partition\"] = i\n",
    "    pred_df = pred_df.append(ped_df)\n",
    "    print(X_train.columns)\n",
    "\n",
    "        \n",
    "#print(\"RF AUC:\",round(roc_auc_score(pred_df.response, pred_df.prediction_rf),4))    \n",
    "print(\"n sample:\",n_sample,\"RF AUC:\",round(roc_auc_score(pred_df.response, pred_df.prediction_rf),4))  \n",
    "outfile.close()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print to outfile \n",
    "#currentDateTime = datetime.now().strftime(\"%m-%d-%Y %H-%M-%S %p\")\n",
    "pred_df.to_csv(r'../../results/5_fold_CV/'+Model+'/pred_df_'+ Model +'prime_1.txt', index=None, sep=' ', mode='w')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.metrics import precision_recall_curve, auc\n",
    "\n",
    "# Calculate precision recall curve and PR AUC score \n",
    "#precision, recall,_= precision_recall_curve(pred_df[['response']], pred_df[['prediction_rf']]) \n",
    "#pr_auc = auc(recall, precision)\n",
    "\n",
    "# Print the PR-AUC Score \n",
    "#print(\"PR-AUC Score:\", pr_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle_model = '../../models_modi/'+sim+'/'+TME_inc+'/rf' + str(i) + '_' + TME_inc +'_' + str(n) + '.pkl'\n",
    "#print(pickle_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle.load(open(pickle_model,\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
